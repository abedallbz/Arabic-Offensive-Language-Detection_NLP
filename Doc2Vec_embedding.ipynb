{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Doc2Vec_embedding.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPUBRn+Z9MBkpQibTct4r0d"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"yhCe2byAQ7A5","colab_type":"code","colab":{}},"source":["# Here the code will be for train a large corpus and embedding with Doc2vec \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RuqWFIKORwUS","colab_type":"code","colab":{}},"source":["from collections import defaultdict\n","from gensim.models import Word2Vec\n","from gensim.test.utils import common_texts\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import utils\n","import csv\n","from tqdm import tqdm\n","import multiprocessing\n","import nltk\n","import random\n","from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n","from sklearn import preprocessing\n","from nltk.stem.isri import ISRIStemmer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4GpsLXbRSOf","colab_type":"code","colab":{}},"source":["######## Train Model doc2Vec #########\n","'''\n","we will pass the train_document file that contain sentences with their Tags \n","and return the trained model\n","...... very sweet ....\n","\n","'''\n","def train_model_doc2vec(train_documents):\n","    cores = multiprocessing.cpu_count()\n","    model_dbow = Doc2Vec(dm=1, vector_size=300, negative=5, hs=0, min_count=2, sample=0, workers=cores, alpha=0.025,\n","                         min_alpha=0.001)\n","    model_dbow.build_vocab([x for x in tqdm(train_documents)])\n","    train_documents = utils.shuffle(train_documents)\n","    model_dbow.train(train_documents, total_examples=len(train_documents), epochs=30)\n","    return model_dbow\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sSF1njscRbXH","colab_type":"code","colab":{}},"source":["############ Train model Dmm ###################\n","def train_model_Dmm(train_tagged):\n","    model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065,\n","                        min_alpha=0.065)\n","    model_dmm.build_vocab([x for x in tqdm(train_tagged)])\n","    for epoch in range(30):\n","        model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged)]), total_examples=len(train_tagged),epochs=1)\n","        model_dmm.alpha -= 0.002\n","        model_dmm.min_alpha = model_dmm.alpha\n","    return  model_dmm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5XXakUKRerf","colab_type":"code","colab":{}},"source":["# we can mix tow model  ConcatenatedDoc2Vec in  gensim\n","def concatenated_doc2vec_with_Dmm(model_dbow , model_dmm):\n","    new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])\n","    return new_model"],"execution_count":0,"outputs":[]}]}